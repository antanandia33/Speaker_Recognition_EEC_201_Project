{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFJKno-AUgm3"
      },
      "source": [
        "### Import Python Libraries and clone Github repository\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGKMcf1iKOM4"
      },
      "outputs": [],
      "source": [
        "# Run this initially\n",
        "import os\n",
        "import numpy as np\n",
        "import scipy.io.wavfile\n",
        "from scipy.fftpack import dct\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "from scipy.sparse import lil_matrix\n",
        "from scipy.signal import spectrogram\n",
        "from scipy.signal import get_window\n",
        "\n",
        "# Github method (Run this once)\n",
        "\n",
        "!git clone https://github.com/antanandia33/Speaker_Recognition_EEC_201_Project\n",
        "%cd Speaker_Recognition_EEC_201_Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_6hdA72Sz4F"
      },
      "source": [
        "### Test 2: Audio Signal Plots and Spectrograms\n",
        "There were 20.48 milliseconds of speech contained in a block of 256 samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCgjv8SwS6fj"
      },
      "outputs": [],
      "source": [
        "train_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Training_Data'\n",
        "\n",
        "train_speakers = []\n",
        "\n",
        "# verify files and put filenames in train_speakers array\n",
        "for filename in os.listdir(train_folder_path):\n",
        "    file_path = os.path.join(train_folder_path, filename)\n",
        "    if os.path.isfile(file_path):  # Ensure it's a file, not a directory\n",
        "        train_speakers.append(filename)\n",
        "\n",
        "num_files = len(train_speakers)\n",
        "num_cols = 4\n",
        "num_rows = int(np.ceil(num_files / 2))\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 20))\n",
        "\n",
        "row = 0\n",
        "col = 0\n",
        "for speaker in train_speakers:\n",
        "    file_path = os.path.join(train_folder_path, speaker)\n",
        "\n",
        "    # Get sample rate and sample values from signal\n",
        "    sample_rate, sig = scipy.io.wavfile.read(file_path)  # File assumed to be in the same directory\n",
        "\n",
        "    # # of milliseconds of speech in 256 samples\n",
        "    samp256_len = 256 / sample_rate * 1000\n",
        "\n",
        "    # Check if .wav file is stereo audio (2 signals)\n",
        "    if len(np.shape(sig)) == 2:\n",
        "      sig = sig[:, 0]   # Get left channel data\n",
        "\n",
        "    # Find STFT of signal\n",
        "    N = 256\n",
        "    M = N//3\n",
        "    f, t_spec, Sxx = signal.stft(sig, fs=sample_rate, nperseg = N)\n",
        "    spect = np.abs(Sxx)\n",
        "    log_power_spect = 10*np.log10(spect ** 2 + 1e-10)\n",
        "\n",
        "    # Plot Spectrogram of signal\n",
        "    pcm1 = axes[row, 2*col].pcolormesh(t_spec, f, log_power_spect, shading = 'auto')\n",
        "    axes[row, 2*col].set_ylabel('Frequency [Hz]')\n",
        "    axes[row, 2*col].set_xlabel('Time [sec]')\n",
        "    axes[row, 2*col].set_title(speaker + ' Power Spectrogram (dB)')\n",
        "    fig.colorbar(pcm1, ax=axes[row, 2*col], label='Power [dB]')\n",
        "\n",
        "    # plot signal\n",
        "    axes[row, (2*col) + 1].plot(sig)\n",
        "    axes[row, (2*col) + 1].set_title(speaker + \" Audio Signal\")\n",
        "    axes[row, (2*col) + 1].set_xlabel(\"n\")\n",
        "    axes[row, (2*col) + 1].set_ylabel(\"Amplitude\")\n",
        "\n",
        "    if (col == 1):\n",
        "      row += 1\n",
        "      col = 0\n",
        "    else:\n",
        "      col += 1\n",
        "\n",
        "print(samp256_len, \" milliseconds in a block of 256 samples\")\n",
        "plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qVj5-7XS6wF"
      },
      "source": [
        "### Test 3: Mel-spaced filter bank responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnK29mN9TDc4"
      },
      "outputs": [],
      "source": [
        "# Test 3: from website: FFT and Filter Banks (melfb function)\n",
        "# Pre Emphasis / Framing / Windowing\n",
        "pre_emphasis = 0.97\n",
        "emphasized_sig = np.append(sig[0], sig[1:] - pre_emphasis * sig[:-1])\n",
        "\n",
        "# Framing\n",
        "frame_size = 0.02048\n",
        "frame_stride = frame_size/3\n",
        "\n",
        "frame_length, frame_step = frame_size * sample_rate, frame_stride * sample_rate  # Convert from seconds to samples\n",
        "signal_length = len(emphasized_sig)\n",
        "frame_length = int(round(frame_length))\n",
        "frame_step = int(round(frame_step))\n",
        "num_frames = int(np.ceil(float(np.abs(signal_length - frame_length)) / frame_step))  # Make sure that we have at least 1 frame\n",
        "\n",
        "pad_signal_length = num_frames * frame_step + frame_length\n",
        "z = np.zeros((pad_signal_length - signal_length))\n",
        "pad_signal = np.append(emphasized_sig, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
        "\n",
        "indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
        "frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
        "\n",
        "# Window\n",
        "frames *= np.hamming(frame_length)\n",
        "\n",
        "# FFT and Power Spectrum\n",
        "NFFT = 512\n",
        "mag_frames = np.absolute(np.fft.rfft(frames, NFFT))  # Magnitude of the FFT\n",
        "pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))  # Power Spectrum\n",
        "\n",
        "# Parameters\n",
        "nfilt = 20  # Number of Mel filters\n",
        "low_freq = 0  # Low frequency (in Hz)\n",
        "high_freq = sample_rate / 2  # High frequency (Nyquist frequency)\n",
        "\n",
        "# Convert to Mel scale\n",
        "low_freq_mel = 0\n",
        "high_freq_mel = (2595 * np.log10(1 + (high_freq / 700)))  # Convert Nyquist frequency to Mel scale\n",
        "mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  # Equally spaced in Mel scale\n",
        "hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel back to Hz\n",
        "\n",
        "# Compute the bin indices for the Mel frequencies\n",
        "bin = np.floor((NFFT + 1) * hz_points / sample_rate)\n",
        "\n",
        "# Initialize the Mel filter bank (nfilt x (NFFT / 2 + 1))\n",
        "fbank = np.zeros((nfilt, int(np.floor(NFFT / 2 + 1))))\n",
        "\n",
        "# Build the triangular filters\n",
        "for m in range(1, nfilt + 1):\n",
        "    f_m_minus = int(bin[m - 1])   # Left boundary of the filter\n",
        "    f_m = int(bin[m])             # Center of the filter\n",
        "    f_m_plus = int(bin[m + 1])    # Right boundary of the filter\n",
        "\n",
        "    for k in range(f_m_minus, f_m):\n",
        "        fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])  # Left side of the triangle\n",
        "\n",
        "    for k in range(f_m, f_m_plus):\n",
        "        fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])  # Right side of the triangle\n",
        "\n",
        "filter_banks = np.dot(pow_frames, fbank.T)\n",
        "filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)  # Numerical Stability\n",
        "filter_banks = 20 * np.log10(filter_banks)  # dB\n",
        "filter_banks -= (np.mean(filter_banks, axis=0) + 1e-8)    # Mean Normalization of filter banks\n",
        "\n",
        "# Time axis\n",
        "times = np.arange(0, num_frames) * frame_stride\n",
        "\n",
        "# Frequency axis (convert Mel filter centers to Hz)\n",
        "hz_points_plot = hz_points[1:-1]  # Ignore the first and last points to match Mel filter bank size\n",
        "\n",
        "plt.figure(figsize=(25, 5))\n",
        "\n",
        "# Plot each filter\n",
        "for i in range(fbank.shape[0]):\n",
        "    plt.plot(np.linspace(0, sample_rate / 2, fbank.shape[1]), fbank[i, :], label=f'Filter {i+1}')\n",
        "\n",
        "# Labels and title\n",
        "plt.title(\"Mel Filter Bank Responses\")\n",
        "plt.xlabel(\"Frequency (Hz)\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.grid(True)\n",
        "plt.legend(loc='upper right', fontsize=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUvym1Oz5kP2"
      },
      "source": [
        "### Test 3: Spectrograms before and after mel-frequency wrapping step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgFwCsFzZtDX"
      },
      "outputs": [],
      "source": [
        "# Before and after Mel frequency wrapping\n",
        "\n",
        "train_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Test_Data'\n",
        "\n",
        "train_speakers = []\n",
        "\n",
        "# verify files and put filenames in train_speakers array\n",
        "for filename in os.listdir(train_folder_path):\n",
        "    file_path = os.path.join(train_folder_path, filename)\n",
        "    if os.path.isfile(file_path):  # Ensure it's a file, not a directory\n",
        "        train_speakers.append(filename)\n",
        "\n",
        "num_files = len(train_speakers)\n",
        "num_cols = 4\n",
        "num_rows = int(np.ceil(num_files / 2))\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 20))\n",
        "\n",
        "row = 0\n",
        "col = 0\n",
        "for speaker in train_speakers:\n",
        "    file_path = os.path.join(train_folder_path, speaker)\n",
        "\n",
        "    # Get sample rate and sample values from signal\n",
        "    sample_rate, sig = scipy.io.wavfile.read(file_path)  # File assumed to be in the same directory\n",
        "\n",
        "    # Check if .wav file is stereo audio (2 signals)\n",
        "    if len(np.shape(sig)) == 2:\n",
        "      sig = sig[:, 0]   # Get left channel data\n",
        "\n",
        "    N = 256   # Segment length\n",
        "    M = N//3  # Segment overlap (overlap by N-M samples)\n",
        "\n",
        "    # Pre Emphasis\n",
        "    pre_emphasis = 0.97\n",
        "    emphasized_sig = np.append(sig[0], sig[1:] - pre_emphasis * sig[:-1])\n",
        "\n",
        "    N = 512\n",
        "    M = N//3\n",
        "\n",
        "    # Framing\n",
        "    frame_size = 0.02048\n",
        "    frame_stride = frame_size/3\n",
        "\n",
        "    frame_length, frame_step = frame_size * sample_rate, frame_stride * sample_rate  # Convert from seconds to samples\n",
        "    signal_length = len(emphasized_sig)\n",
        "    frame_length = int(round(frame_length))\n",
        "    frame_step = int(round(frame_step))\n",
        "    num_frames = int(np.ceil(float(np.abs(signal_length - frame_length)) / frame_step))  # Make sure that we have at least 1 frame\n",
        "\n",
        "    pad_signal_length = num_frames * frame_step + frame_length\n",
        "    z = np.zeros((pad_signal_length - signal_length))\n",
        "    pad_signal = np.append(emphasized_sig, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
        "\n",
        "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
        "    frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
        "\n",
        "    # Window\n",
        "    frames *= np.hamming(frame_length)\n",
        "\n",
        "    # FFT and Power Spectrum\n",
        "    NFFT = 512\n",
        "    mag_frames = np.absolute(np.fft.rfft(frames, NFFT))  # Magnitude of the FFT\n",
        "    pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))  # Power Spectrum\n",
        "\n",
        "    # Parameters\n",
        "    nfilt = 20  # Number of Mel filters\n",
        "    low_freq = 0  # Low frequency (in Hz)\n",
        "    high_freq = sample_rate / 2  # High frequency (Nyquist frequency)\n",
        "\n",
        "    # Convert to Mel scale (melfb)\n",
        "    low_freq_mel = 0\n",
        "    high_freq_mel = (2595 * np.log10(1 + (high_freq / 700)))  # Convert Nyquist frequency to Mel scale\n",
        "    mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  # Equally spaced in Mel scale\n",
        "    hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel back to Hz\n",
        "\n",
        "    # Compute the bin indices for the Mel frequencies\n",
        "    bin = np.floor((NFFT + 1) * hz_points / sample_rate)\n",
        "\n",
        "    # Initialize the Mel filter bank (nfilt x (NFFT / 2 + 1))\n",
        "    fbank = np.zeros((nfilt, int(np.floor(NFFT / 2 + 1))))\n",
        "\n",
        "    # Build the triangular filters\n",
        "    for m in range(1, nfilt + 1):\n",
        "        f_m_minus = int(bin[m - 1])   # Left boundary of the filter\n",
        "        f_m = int(bin[m])             # Center of the filter\n",
        "        f_m_plus = int(bin[m + 1])    # Right boundary of the filter\n",
        "\n",
        "        for k in range(f_m_minus, f_m):\n",
        "            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])  # Left side of the triangle\n",
        "\n",
        "        for k in range(f_m, f_m_plus):\n",
        "            fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])  # Right side of the triangle\n",
        "\n",
        "    filter_banks = np.dot(pow_frames, fbank.T)\n",
        "    filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)  # Numerical Stability\n",
        "    filter_banks = 20 * np.log10(filter_banks)  # dB\n",
        "    filter_banks -= (np.mean(filter_banks, axis=0) + 1e-8)    # Mean Normalization of filter banks\n",
        "\n",
        "    # Time axis\n",
        "    times = np.arange(0, num_frames) * frame_stride\n",
        "\n",
        "    # Frequency axis (convert Mel filter centers to Hz)\n",
        "    hz_points_plot = hz_points[1:-1]  # Ignore the first and last points to match Mel filter bank size\n",
        "\n",
        "    # Plot Spectrogram before frequency wrapping\n",
        "    pcm1 = axes[row, 2*col].pcolormesh(times, np.linspace(0, sample_rate / 2, NFFT // 2 + 1), 10 * np.log10(pow_frames.T), shading = 'auto')\n",
        "    axes[row, 2*col].set_ylabel('Frequency [Hz]')\n",
        "    axes[row, 2*col].set_xlabel('Time [sec]')\n",
        "    axes[row, 2*col].set_title(speaker + ' Spectrogram before Frequency Wrapping ')\n",
        "    fig.colorbar(pcm1, ax=axes[row, 2*col], label='Power [dB]')\n",
        "\n",
        "    # Plot Spectrogram after frequency wrapping\n",
        "    pcm2 = axes[row, (2*col) + 1].pcolormesh(times, hz_points_plot, filter_banks.T, shading = 'auto')\n",
        "    axes[row, (2*col) + 1].set_ylabel('Frequency [Hz]')\n",
        "    axes[row, (2*col) + 1].set_xlabel('Time [sec]')\n",
        "    axes[row, (2*col) + 1].set_title(speaker + ' Spectrogram after Frequency Wrapping ')\n",
        "    fig.colorbar(pcm1, ax=axes[row, (2*col) + 1], label='Power [dB]')\n",
        "\n",
        "    if (col == 1):\n",
        "      row += 1\n",
        "      col = 0\n",
        "    else:\n",
        "      col += 1\n",
        "\n",
        "\n",
        "plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiDoZi2X1guY"
      },
      "source": [
        "Test 3: melfb function \\\\\n",
        "The melfb function computes filter banks that are uniformly spaced on the mel scale. This is used to mimic the behavior of human hearing, in which frequencies are perceived in the mel frequency scale with linear spacing below 1000 Hz and logarithmic spacing above 1000 Hz. \\\\\n",
        "The DCT of these of these filter banks can be computed to find the Mel-Frequency Cepstrum Coefficients of the signal in order to train a model for feature matching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1tS7miTy8xI"
      },
      "outputs": [],
      "source": [
        "# Melfb function\n",
        "def melfb(num_filts, fft_len, fs, pframes):\n",
        "    # Parameters\n",
        "    pow_frames = pframes\n",
        "    sample_rate = fs\n",
        "    NFFT = fft_len\n",
        "    nfilt = num_filts  # Number of Mel filters\n",
        "\n",
        "    low_freq = 0  # Low frequency (in Hz)\n",
        "    high_freq = sample_rate / 2  # High frequency (Nyquist frequency)\n",
        "\n",
        "    # Convert to Mel scale (melfb)\n",
        "    low_freq_mel = 0\n",
        "    high_freq_mel = (2595 * np.log10(1 + (high_freq / 700)))  # Convert Nyquist frequency to Mel scale\n",
        "    mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  # Equally spaced in Mel scale\n",
        "    hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel back to Hz\n",
        "\n",
        "    # Compute the bin indices for the Mel frequencies\n",
        "    bin = np.floor((NFFT + 1) * hz_points / sample_rate)\n",
        "\n",
        "    # Initialize the Mel filter bank (nfilt x (NFFT / 2 + 1))\n",
        "    fbank = np.zeros((nfilt, int(np.floor(NFFT / 2 + 1))))\n",
        "\n",
        "    # Build the triangular filters\n",
        "    for m in range(1, nfilt + 1):\n",
        "        f_m_minus = int(bin[m - 1])   # Left boundary of the filter\n",
        "        f_m = int(bin[m])             # Center of the filter\n",
        "        f_m_plus = int(bin[m + 1])    # Right boundary of the filter\n",
        "\n",
        "        for k in range(f_m_minus, f_m):\n",
        "            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])  # Left side of the triangle\n",
        "\n",
        "        for k in range(f_m, f_m_plus):\n",
        "            fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])  # Right side of the triangle\n",
        "\n",
        "    filter_banks = np.dot(pow_frames, fbank.T)\n",
        "    filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)  # Numerical Stability\n",
        "    filter_banks = 20 * np.log10(filter_banks)  # dB\n",
        "    filter_banks -= (np.mean(filter_banks, axis=0) + 1e-8)    # Mean Normalization of filter banks\n",
        "\n",
        "    return filter_banks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "186nRd6ApNXe"
      },
      "source": [
        "Test 4: MFCC function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KD0w9jC6kqV1"
      },
      "outputs": [],
      "source": [
        "def mfcc (filepath):\n",
        "  # Get sample rate and sample values from signal\n",
        "  sample_rate, sig = scipy.io.wavfile.read(filepath)  # File assumed to be in the same directory\n",
        "  if len(sig.shape) > 1:\n",
        "    sig = np.mean(sig, axis=1)\n",
        "\n",
        "  f, t_spec, Sxx = signal.stft(sig, fs=sample_rate, nperseg = N)\n",
        "  spect = np.abs(Sxx)\n",
        "  log_power_spect = 10*np.log10(spect ** 2 + 1e-10)\n",
        "\n",
        "  # Pre Emphasis\n",
        "  pre_emphasis = 0.97\n",
        "  emphasized_sig = np.append(sig[0], sig[1:] - pre_emphasis * sig[:-1])\n",
        "\n",
        "  # Framing\n",
        "  frame_size = 0.02048\n",
        "  frame_stride = frame_size/3\n",
        "\n",
        "  frame_length, frame_step = frame_size * sample_rate, frame_stride * sample_rate  # Convert from seconds to samples\n",
        "  signal_length = len(emphasized_sig)\n",
        "  frame_length = int(round(frame_length))\n",
        "  frame_step = int(round(frame_step))\n",
        "  num_frames = int(np.ceil(float(np.abs(signal_length - frame_length)) / frame_step))  # Make sure that we have at least 1 frame\n",
        "\n",
        "  pad_signal_length = num_frames * frame_step + frame_length\n",
        "  z = np.zeros((pad_signal_length - signal_length))\n",
        "  pad_signal = np.append(emphasized_sig, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
        "\n",
        "  indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
        "  frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
        "\n",
        "  # Window\n",
        "  frames *= np.hamming(frame_length)\n",
        "\n",
        "  # FFT and Power Spectrum\n",
        "  NFFT = 512\n",
        "  mag_frames = np.absolute(np.fft.rfft(frames, NFFT))  # Magnitude of the FFT\n",
        "  pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))  # Power Spectrum\n",
        "\n",
        "  # Parameters\n",
        "  nfilt = 20  # Number of Mel filters\n",
        "  low_freq = 0  # Low frequency (in Hz)\n",
        "  high_freq = sample_rate / 2  # High frequency (Nyquist frequency)\n",
        "\n",
        "\n",
        "  # Apply mel frequency wrapping to STFT of signal\n",
        "  filter_banks = melfb(nfilt, NFFT, sample_rate, pow_frames)\n",
        "\n",
        "  # Time axis\n",
        "  times = np.arange(0, num_frames) * frame_stride\n",
        "\n",
        "  # Frequency axis (convert Mel filter centers to Hz)\n",
        "  hz_points_plot = hz_points[1:-1]  # Ignore the first and last points to match Mel filter bank size\n",
        "\n",
        "  # Cepstrum coefficients\n",
        "  num_ceps = 19\n",
        "  cep_lifter = 3\n",
        "\n",
        "  cep_coeff = dct(filter_banks, type=2, axis=1, norm='ortho')[:, 1 : (num_ceps + 1)] # Keep 2-13\n",
        "\n",
        "  (nframes, ncoeff) = cep_coeff.shape\n",
        "  n = np.arange(ncoeff)\n",
        "  lift = 1 + (cep_lifter / 2) * np.sin(np.pi * n / cep_lifter)\n",
        "  cep_coeff *= lift\n",
        "\n",
        "  # Mean Normalization of MFCC coefficients\n",
        "  cep_coeff -= (np.mean(cep_coeff, axis=0) + 1e-8)\n",
        "\n",
        "  return cep_coeff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUSMD3XDTqne"
      },
      "source": [
        "## Part C - Vector Quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPgpD-6VTsBv"
      },
      "source": [
        "#### Test 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRyuE_c2Trsr"
      },
      "outputs": [],
      "source": [
        "# Plot mfcc\n",
        "# Test 5\n",
        "\n",
        "speaker_1_mfcc = mfcc(\"/content/Speaker_Recognition_EEC_201_Project/Training_Data/s1.wav\")\n",
        "speaker_2_mfcc = mfcc(\"/content/Speaker_Recognition_EEC_201_Project/Training_Data/s2.wav\")\n",
        "\n",
        "# get the 5th and 6th coefficients of speaker 1 and 2\n",
        "x1, y1 = speaker_1_mfcc[:, 4], speaker_1_mfcc[:, 5]\n",
        "x2, y2 = speaker_2_mfcc[:, 4], speaker_2_mfcc[:, 5]\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.scatter(x1, y1, color='blue', marker='o', label='Speaker 1')\n",
        "plt.scatter(x2, y2, color='red', marker='x', label='Speaker 2')\n",
        "plt.xlabel('mfcc-5')\n",
        "plt.ylabel('mfcc-6')\n",
        "plt.title('mfcc vector space (mfcc-5 x mfcc-6)')\n",
        "plt.legend()\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOh3XOUygH8R"
      },
      "source": [
        "### Train using LGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCiNDdR3gK7l"
      },
      "outputs": [],
      "source": [
        "# LGB Algorithm\n",
        "def LGB(features, centroids, epsilon):\n",
        "  \"\"\"\n",
        "  inputs\n",
        "  features - NxM array frames x features\n",
        "  centroids - Number of Centroids/Clusters\n",
        "  epsilon - threshold for convergence\n",
        "\n",
        "  output\n",
        "  codebook - NxM array of centroids x features\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize with a single-vector codebook\n",
        "  codebook = np.array([np.mean(features, axis=0)])\n",
        "\n",
        "  # while the size of the codebook is less than the wanted number of centroids\n",
        "  while len(codebook) < centroids:\n",
        "\n",
        "    # Split centroids\n",
        "    new_codebook = []\n",
        "    for code_vector in codebook:\n",
        "        new_codebook.append(code_vector + epsilon)\n",
        "        new_codebook.append(code_vector - epsilon)\n",
        "\n",
        "    new_codebook = np.array(new_codebook)\n",
        "\n",
        "    codebook = new_codebook\n",
        "\n",
        "    previous_distortion = np.sum((features - codebook[0, :]) ** 2) / features.shape[0]\n",
        "\n",
        "    # nearest neighbor search\n",
        "    while True:\n",
        "        distances = np.linalg.norm(features[:, np.newaxis, :] - codebook, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "\n",
        "        new_codebook = []\n",
        "        for i in range(len(codebook)):\n",
        "            if np.any(labels == i):\n",
        "                new_codebook.append(features[labels == i].mean(axis=0))\n",
        "            else:\n",
        "                new_codebook.append(codebook[i])\n",
        "        new_codebook = np.array(new_codebook)\n",
        "\n",
        "        # compute distortion\n",
        "        distortion = np.mean(np.min(distances, axis=1))\n",
        "\n",
        "        # break if average distortion falls below epsilon\n",
        "        if abs(previous_distortion - distortion) / distortion < epsilon:\n",
        "          break\n",
        "        previous_distortion = distortion\n",
        "        codebook = new_codebook\n",
        "\n",
        "  return codebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwK5amPGEPE8"
      },
      "source": [
        "### Test 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTcrkoyEEdj9"
      },
      "source": [
        "#### Train Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t65CQMXqEgXN"
      },
      "outputs": [],
      "source": [
        "# runs LGB on every speaker mfcc and generates a codebook\n",
        "# returns a list of codebooks\n",
        "def train(speaker_mfccs):\n",
        "  codebookList = []\n",
        "  for speaker in speaker_mfccs:\n",
        "    codebook = LGB(speaker, 16, 0.001)\n",
        "    codebookList.append(codebook)\n",
        "  return codebookList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Jjzuf1OEQJP"
      },
      "outputs": [],
      "source": [
        "# Test 6\n",
        "speaker_1_mfcc = mfcc(\"/content/Speaker_Recognition_EEC_201_Project/Training_Data/s1.wav\")\n",
        "speaker_2_mfcc = mfcc(\"/content/Speaker_Recognition_EEC_201_Project/Training_Data/s2.wav\")\n",
        "\n",
        "# get the 5th and 6th coefficients\n",
        "x1, y1 = speaker_1_mfcc[:, 4], speaker_1_mfcc[:, 5]\n",
        "x2, y2 = speaker_2_mfcc[:, 4], speaker_2_mfcc[:, 5]\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.scatter(x1, y1, color='blue', marker='o', label='Speaker 1', alpha=0.2)\n",
        "plt.scatter(x2, y2, color='red', marker='x', label='Speaker 2', alpha=0.2)\n",
        "\n",
        "# train\n",
        "codebookList = train([speaker_1_mfcc, speaker_2_mfcc])\n",
        "\n",
        "# get the 5th and 6th dimensions of the centroids\n",
        "x1, y1 = codebookList[0][:, 4], codebookList[0][:, 5]\n",
        "x2, y2 = codebookList[1][:, 4], codebookList[1][:, 5]\n",
        "\n",
        "plt.scatter(x1, y1, color='blue', marker='D', label='Speaker 1 Centroid')\n",
        "plt.scatter(x2, y2, color='red', marker='D', label='Speaker 2 Centroid')\n",
        "\n",
        "plt.xlabel('mfcc-5')\n",
        "plt.ylabel('mfcc-6')\n",
        "plt.title('Codewords vector space (mfcc-5 x mfcc-6)')\n",
        "plt.legend()\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRSYPEEletct"
      },
      "source": [
        "## Part D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuRzlN7oERZh"
      },
      "source": [
        "### Speaker Prediction Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtMAppsdEX8g"
      },
      "outputs": [],
      "source": [
        "# For every codebook, calculate the average distance between the test_mfcc vectors and the code book centroids\n",
        "# The test_mfcc codebook pair with the minimum average distance is the best match\n",
        "# returns the index of the codebook with the best match\n",
        "def predict(codebookList, test_mfcc):\n",
        "\n",
        "  distances = np.array([])\n",
        "  for codebook in codebookList:\n",
        "    vector_centroid_distances = np.linalg.norm(test_mfcc[:, np.newaxis, :] - codebook, axis=2)\n",
        "    avg_vector_centroid_distance = np.mean(np.min(vector_centroid_distances, axis=1))\n",
        "    distances = np.append(distances, avg_vector_centroid_distance)\n",
        "\n",
        "  return np.argmin(distances)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5N_FUU-PI8Z"
      },
      "source": [
        "### Test 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14Ek1ilSQkJs"
      },
      "outputs": [],
      "source": [
        "# get mfccs for all train speakers\n",
        "train_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Training_Data'\n",
        "\n",
        "train_speakers = []\n",
        "\n",
        "for filename in os.listdir(train_folder_path):\n",
        "    file_path = os.path.join(train_folder_path, filename)\n",
        "    if os.path.isfile(file_path):  # Ensure it's a file, not a directory\n",
        "        train_speakers.append(filename)\n",
        "\n",
        "train_speaker_mfccs = []\n",
        "\n",
        "for speaker in train_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(train_folder_path, speaker))\n",
        "  train_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "\n",
        "# train codebooks\n",
        "codeBooks = train(train_speaker_mfccs)\n",
        "\n",
        "# get mfccs for all test speakers\n",
        "test_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Test_Data'\n",
        "\n",
        "test_speakers = []\n",
        "\n",
        "for filename in os.listdir(test_folder_path):\n",
        "    file_path = os.path.join(test_folder_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        test_speakers.append(filename)\n",
        "\n",
        "\n",
        "test_speaker_mfccs = []\n",
        "\n",
        "for speaker in test_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(test_folder_path, speaker))\n",
        "  test_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# reference prediction with training speakers\n",
        "num_correct_train = 0\n",
        "for train_speaker, speaker_mfcc in enumerate(train_speaker_mfccs):\n",
        "  prediction = predict(codeBooks, speaker_mfcc)\n",
        "  if train_speakers[prediction] == train_speakers[train_speaker]:\n",
        "    num_correct_train += 1\n",
        "    print(f\"CORRECT: train_speaker: {train_speakers[train_speaker]} predicted as: {train_speakers[prediction]}\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: train_speaker: {train_speakers[train_speaker]} predicted as: {train_speakers[prediction]}\")\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {num_correct_train * 100 / len(train_speaker_mfccs)}%\")\n",
        "\n",
        "# prediction with test speakers\n",
        "num_correct = 0\n",
        "for test_speaker, speaker_mfcc in enumerate(test_speaker_mfccs):\n",
        "  prediction = predict(codeBooks, speaker_mfcc)\n",
        "\n",
        "  if train_speakers[prediction] == test_speakers[test_speaker]:\n",
        "    num_correct += 1\n",
        "    print(f\"CORRECT: test_speaker: {test_speakers[test_speaker]} predicted as: {train_speakers[prediction]}\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: test_speaker: {test_speakers[test_speaker]} predicted as: {train_speakers[prediction]}\")\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {num_correct * 100 / len(test_speaker_mfccs)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Including the new teammates' recordings\n",
        "# get mfccs for all train speakers\n",
        "train_folder_path = '/content/Speaker_Recognition_EEC_201_Project/New Zero Training'\n",
        "\n",
        "train_speakers = []\n",
        "\n",
        "for filename in os.listdir(train_folder_path):\n",
        "    file_path = os.path.join(train_folder_path, filename)\n",
        "    if os.path.isfile(file_path):  # Ensure it's a file, not a directory\n",
        "        train_speakers.append(filename)\n",
        "\n",
        "train_speaker_mfccs = []\n",
        "\n",
        "for speaker in train_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(train_folder_path, speaker))\n",
        "  train_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "\n",
        "# train codebooks\n",
        "codeBooks = train(train_speaker_mfccs)\n",
        "\n",
        "# get mfccs for all test speakers\n",
        "test_folder_path = '/content/Speaker_Recognition_EEC_201_Project/New Zero Testing'\n",
        "\n",
        "test_speakers = []\n",
        "\n",
        "for filename in os.listdir(test_folder_path):\n",
        "    file_path = os.path.join(test_folder_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        test_speakers.append(filename)\n",
        "\n",
        "\n",
        "test_speaker_mfccs = []\n",
        "\n",
        "for speaker in test_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(test_folder_path, speaker))\n",
        "  test_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# reference prediction with training speakers\n",
        "num_correct_train = 0\n",
        "for train_speaker, speaker_mfcc in enumerate(train_speaker_mfccs):\n",
        "  prediction = predict(codeBooks, speaker_mfcc)\n",
        "  if train_speakers[prediction] == train_speakers[train_speaker]:\n",
        "    num_correct_train += 1\n",
        "    print(f\"CORRECT: train_speaker: {train_speakers[train_speaker]} predicted as: {train_speakers[prediction]}\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: train_speaker: {train_speakers[train_speaker]} predicted as: {train_speakers[prediction]}\")\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {num_correct_train * 100 / len(train_speaker_mfccs)}%\")\n",
        "\n",
        "# prediction with test speakers\n",
        "num_correct = 0\n",
        "for test_speaker, speaker_mfcc in enumerate(test_speaker_mfccs):\n",
        "  prediction = predict(codeBooks, speaker_mfcc)\n",
        "\n",
        "  if train_speakers[prediction] == test_speakers[test_speaker]:\n",
        "    num_correct += 1\n",
        "    print(f\"CORRECT: test_speaker: {test_speakers[test_speaker]} predicted as: {train_speakers[prediction]}\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: test_speaker: {test_speakers[test_speaker]} predicted as: {train_speakers[prediction]}\")\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {num_correct * 100 / len(test_speaker_mfccs)}%\")"
      ],
      "metadata": {
        "id": "glQ1aK2VYgMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-vJbFReYWTz"
      },
      "source": [
        "### Test 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhpamvAPc4Kx"
      },
      "source": [
        "#### Generate New Test Set with Notched Signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmtdOyj7YYLv"
      },
      "outputs": [],
      "source": [
        "from scipy.signal import iirnotch, filtfilt, freqz\n",
        "import scipy.io.wavfile as wavfile\n",
        "\n",
        "# applies notch at a given frequency on a signal\n",
        "def apply_notch(signal, fs, freq, Q):\n",
        "    b, a = iirnotch(freq, Q, fs)\n",
        "    filtered_signal = filtfilt(b, a, signal)\n",
        "    return filtered_signal\n",
        "\n",
        "# saves the signal as a wav file\n",
        "def save_wav(filename, data, sample_rate):\n",
        "    wavfile.write(filename, sample_rate, data)\n",
        "\n",
        "test_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Test_Data'\n",
        "\n",
        "test_speakers = []\n",
        "\n",
        "for filename in os.listdir(test_folder_path):\n",
        "    file_path = os.path.join(test_folder_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        test_speakers.append(filename)\n",
        "\n",
        "# make a notch folder\n",
        "notch_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Notched_Test_Data'\n",
        "os.makedirs(notch_folder_path, exist_ok=True)\n",
        "\n",
        "# apply notch on every speaker and save it into the notch folder\n",
        "for speaker in test_speakers:\n",
        "  fs, sig = wavfile.read(os.path.join(test_folder_path, speaker))\n",
        "  notched_signal = apply_notch(sig, fs, 60, 30)\n",
        "  new_file_name = os.path.join(notch_folder_path, speaker)\n",
        "  save_wav(new_file_name, notched_signal, fs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11YDyVX9eZSP"
      },
      "source": [
        "#### Predict on Notched Signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM9hRuunecjP"
      },
      "outputs": [],
      "source": [
        "# get mfccs for all test speakers\n",
        "test_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Notched_Test_Data'\n",
        "\n",
        "test_speakers = []\n",
        "\n",
        "for filename in os.listdir(test_folder_path):\n",
        "    file_path = os.path.join(test_folder_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        test_speakers.append(filename)\n",
        "\n",
        "test_speaker_mfccs = []\n",
        "\n",
        "for speaker in test_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(test_folder_path, speaker))\n",
        "  test_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# prediction with test speakers\n",
        "num_correct = 0\n",
        "for test_speaker, speaker_mfcc in enumerate(test_speaker_mfccs):\n",
        "  prediction = predict(codeBooks, speaker_mfcc)\n",
        "\n",
        "  if train_speakers[prediction] == test_speakers[test_speaker]:\n",
        "    num_correct += 1\n",
        "    print(f\"CORRECT: test_speaker: {test_speakers[test_speaker]} predicted as: {train_speakers[prediction]}\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: test_speaker: {test_speakers[test_speaker]} predicted as: {train_speakers[prediction]}\")\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {num_correct * 100 / len(test_speaker_mfccs)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNxNkXQtgHaW"
      },
      "source": [
        "### Test 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldlxwXXRiDFS"
      },
      "source": [
        "#### Original Speakers + 10 random Students with speech \"zero\"\n",
        "\n",
        "The new accuracy after adding the 10 random student saying \"zero\" to the original data set is 72.22%, which is less than the 75% accuracy from using the original data by itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wAfgYtXgIIX"
      },
      "outputs": [],
      "source": [
        "# get mfccs for all train speakers\n",
        "train_folder_path = '/content/Speaker_Recognition_EEC_201_Project/original_and_10_students_zero_train'\n",
        "\n",
        "train_speakers = []\n",
        "\n",
        "for filename in os.listdir(train_folder_path):\n",
        "    file_path = os.path.join(train_folder_path, filename)\n",
        "    if os.path.isfile(file_path):  # Ensure it's a file, not a directory\n",
        "        train_speakers.append(filename)\n",
        "\n",
        "train_speaker_mfccs = []\n",
        "\n",
        "for speaker in train_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(train_folder_path, speaker))\n",
        "  train_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "\n",
        "# train codebooks\n",
        "codeBooks = train(train_speaker_mfccs)\n",
        "\n",
        "# get mfccs for all test speakers\n",
        "test_folder_path = '/content/Speaker_Recognition_EEC_201_Project/original_and_10_students_zero_test'\n",
        "\n",
        "test_speakers = []\n",
        "\n",
        "for filename in os.listdir(test_folder_path):\n",
        "    file_path = os.path.join(test_folder_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        test_speakers.append(filename)\n",
        "\n",
        "\n",
        "test_speaker_mfccs = []\n",
        "\n",
        "for speaker in test_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(test_folder_path, speaker))\n",
        "  test_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# reference prediction with training speakers\n",
        "num_correct_train = 0\n",
        "for train_speaker, speaker_mfcc in enumerate(train_speaker_mfccs):\n",
        "  prediction = predict(codeBooks, speaker_mfcc)\n",
        "  if train_speakers[prediction] == train_speakers[train_speaker]:\n",
        "    num_correct_train += 1\n",
        "    print(f\"CORRECT: train_speaker: {train_speakers[train_speaker]} predicted as: {train_speakers[prediction]}\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: train_speaker: {train_speakers[train_speaker]} predicted as: {train_speakers[prediction]}\")\n",
        "\n",
        "print(f\"Accuracy: {num_correct_train * 100 / len(train_speaker_mfccs)}%\")\n",
        "\n",
        "# predict\n",
        "num_correct = 0\n",
        "for test_speaker, speaker_mfcc in enumerate(test_speaker_mfccs):\n",
        "  prediction = predict(codeBooks, speaker_mfcc)\n",
        "\n",
        "  if train_speakers[prediction] == test_speakers[test_speaker]:\n",
        "    num_correct += 1\n",
        "    print(f\"CORRECT: test_speaker: {test_speakers[test_speaker]} predicted as: {train_speakers[prediction]}\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: test_speaker: {test_speakers[test_speaker]} predicted as: {train_speakers[prediction]}\")\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {num_correct * 100 / len(test_speaker_mfccs)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vnrFWHBlkjq"
      },
      "source": [
        "### Test 10a"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train using 0 and 12 speeches"
      ],
      "metadata": {
        "id": "VFx79LPanmly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get mfccs for all train 0 speakers\n",
        "train0_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Zero-Training'\n",
        "\n",
        "train0_speakers = []\n",
        "\n",
        "# verify files and put filenames into train5_speakers\n",
        "for filename in os.listdir(train0_folder_path):\n",
        "    file_path = os.path.join(train0_folder_path, filename)\n",
        "    if os.path.isfile(file_path):  # Ensure it's a file, not a directory\n",
        "        train0_speakers.append(filename)\n",
        "\n",
        "# Find MFCCs for train 0\n",
        "train0_speaker_mfccs = []\n",
        "for speaker in train0_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(train0_folder_path, speaker))\n",
        "  train0_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# train codebooks for speech 0\n",
        "codeBooks_0 = train(train0_speaker_mfccs)\n",
        "\n",
        "# get mfccs for all train 11 speakers\n",
        "train12_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Twelve-Training'\n",
        "\n",
        "train12_speakers = []\n",
        "\n",
        "# verify files and put filenames into train11_speakers\n",
        "for filename in os.listdir(train12_folder_path):\n",
        "    file_path = os.path.join(train12_folder_path, filename)\n",
        "    if os.path.isfile(file_path):  # Ensure it's a file, not a directory\n",
        "        train12_speakers.append(filename)\n",
        "\n",
        "train12_speaker_mfccs = []\n",
        "\n",
        "# Find MFCCs for train 11\n",
        "for speaker in train12_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(train12_folder_path, speaker))\n",
        "  train12_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# train codebooks for speech 11\n",
        "codeBooks_12 = train(train12_speaker_mfccs)"
      ],
      "metadata": {
        "id": "qFIeihYQnqwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1: If we use \"twelve\" to identify speakers, what is the accuracy versus the system that uses \"zero\"?\n",
        "\n",
        "Using \"zero\" had an accuracy of about 72.22% and using \"twelve\" had an accuracy of about 66.67%."
      ],
      "metadata": {
        "id": "sMJyknYVoJIm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using \"zero\""
      ],
      "metadata": {
        "id": "_NAdsMZR-2XN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get mfccs for all test speakers\n",
        "test_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Zero-Testing'\n",
        "\n",
        "test0_speakers = []\n",
        "\n",
        "# verify files and put filenames into train5_speakers\n",
        "for filename in os.listdir(test_folder_path):\n",
        "    file_path = os.path.join(test_folder_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        test0_speakers.append(filename)\n",
        "\n",
        "# Find MFCCs for train 5\n",
        "test0_speaker_mfccs = []\n",
        "for speaker in test0_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(test_folder_path, speaker))\n",
        "  test0_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# reference prediction with training speakers\n",
        "num_correct_train = 0\n",
        "for train_speaker, speaker_mfcc in enumerate(train0_speaker_mfccs):\n",
        "  prediction = predict(codeBooks_0, speaker_mfcc)\n",
        "  if train0_speakers[prediction] == train0_speakers[train_speaker]:\n",
        "    num_correct_train += 1\n",
        "    print(f\"CORRECT: train_speaker: {train0_speakers[train_speaker]} predicted as: {train0_speakers[prediction]}\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: train_speaker: {train0_speakers[train_speaker]} predicted as: {train0_speakers[prediction]}\")\n",
        "\n",
        "print(f\"Accuracy: {num_correct_train * 100 / len(train0_speaker_mfccs)}%\")\n",
        "\n",
        "# prediction with test speakers\n",
        "num_correct = 0\n",
        "for test_speaker, speaker_mfcc in enumerate(test0_speaker_mfccs):\n",
        "  prediction = predict(codeBooks_0, speaker_mfcc)\n",
        "\n",
        "  if train0_speakers[prediction] == test0_speakers[test_speaker]:\n",
        "    num_correct += 1\n",
        "    print(f\"CORRECT: test_speaker: {test0_speakers[test_speaker]} predicted as: {train0_speakers[prediction]}\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: test_speaker: {test0_speakers[test_speaker]} predicted as: {train0_speakers[prediction]}\")\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {num_correct * 100 / len(test0_speaker_mfccs)}%\")"
      ],
      "metadata": {
        "id": "KTOF9XGLoRfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using \"twelve\""
      ],
      "metadata": {
        "id": "hTXluHhCGXAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get mfccs for all test speakers\n",
        "test_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Twelve-Testing'\n",
        "\n",
        "test12_speakers = []\n",
        "\n",
        "# verify files and put filenames into train5_speakers\n",
        "for filename in os.listdir(test_folder_path):\n",
        "    file_path = os.path.join(test_folder_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        test12_speakers.append(filename)\n",
        "\n",
        "# Find MFCCs for train 5\n",
        "test12_speaker_mfccs = []\n",
        "for speaker in test12_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(test_folder_path, speaker))\n",
        "  test12_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# reference prediction with training speakers\n",
        "num_correct_train = 0\n",
        "for train_speaker, speaker_mfcc in enumerate(train12_speaker_mfccs):\n",
        "  prediction = predict(codeBooks_12, speaker_mfcc)\n",
        "  if train12_speakers[prediction] == train12_speakers[train_speaker]:\n",
        "    num_correct_train += 1\n",
        "    print(f\"CORRECT: train_speaker: {train12_speakers[train_speaker]} predicted as: {train12_speakers[prediction]}\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: train_speaker: {train12_speakers[train_speaker]} predicted as: {train12_speakers[prediction]}\")\n",
        "\n",
        "print(f\"Accuracy: {num_correct_train * 100 / len(train12_speaker_mfccs)}%\")\n",
        "\n",
        "# prediction with test speakers\n",
        "num_correct = 0\n",
        "for test_speaker, speaker_mfcc in enumerate(test12_speaker_mfccs):\n",
        "  prediction = predict(codeBooks_12, speaker_mfcc)\n",
        "\n",
        "  if train12_speakers[prediction] == test12_speakers[test_speaker]:\n",
        "    num_correct += 1\n",
        "    print(f\"CORRECT: test_speaker: {test12_speakers[test_speaker]} predicted as: {train12_speakers[prediction]}\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: test_speaker: {test12_speakers[test_speaker]} predicted as: {train12_speakers[prediction]}\")\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {num_correct * 100 / len(test12_speaker_mfccs)}%\")"
      ],
      "metadata": {
        "id": "90iq15WcGYkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2: If we train a whole system that tries to identify a) which speaker, and b) whether the speech is \"zero\" or \"twelve\", how accurate is your system?\n",
        "The accuracy for our system trained to identify which speaker and whether the speech is zero or twelve is 69.44%.\n"
      ],
      "metadata": {
        "id": "ntoiWTzooMy_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nDIkUt8U6GH"
      },
      "outputs": [],
      "source": [
        "# creates a hash map that maps the speaker to a list of it's own codebooks\n",
        "def train_two(train_speakers1, mfccs_1, train_speakers2, mfccs_2):\n",
        "  codeBooks = {}\n",
        "  for i, speaker in enumerate(train_speakers1):\n",
        "    codebook = LGB(mfccs_1[i], 16, 0.001)\n",
        "    codeBooks[speaker] = [codebook]\n",
        "\n",
        "  for i, speaker in enumerate(train_speakers2):\n",
        "    codebook = LGB(mfccs_2[i], 16, 0.001)\n",
        "    codeBooks[speaker].append(codebook)\n",
        "\n",
        "  return codeBooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQiWPVXqqZ13"
      },
      "outputs": [],
      "source": [
        "# To identify between two numbers\n",
        "def predict_two(codebookListMain, test_mfcc, train_speakers):\n",
        "\n",
        "  distances1 = np.array([])\n",
        "  distances2 = np.array([])\n",
        "\n",
        "  codebookList1 = []\n",
        "  codebookList2 = []\n",
        "\n",
        "  # Separate the two codebook lists\n",
        "  for speaker in codebookListMain:\n",
        "    codebookList1.append(codebookListMain[speaker][0])\n",
        "    codebookList2.append(codebookListMain[speaker][1])\n",
        "\n",
        "  # Find average centroid distances for first\n",
        "  for codebook in codebookList1:\n",
        "    vector_centroid_distances = np.linalg.norm(test_mfcc[:, np.newaxis, :] - codebook, axis=2)\n",
        "    avg_vector_centroid_distance = np.mean(np.min(vector_centroid_distances, axis=1))\n",
        "    distances1 = np.append(distances1, avg_vector_centroid_distance)\n",
        "\n",
        "  # Find average centroid distances for second\n",
        "  for codebook in codebookList2:\n",
        "    vector_centroid_distances = np.linalg.norm(test_mfcc[:, np.newaxis, :] - codebook, axis=2)\n",
        "    avg_vector_centroid_distance = np.mean(np.min(vector_centroid_distances, axis=1))\n",
        "    distances2 = np.append(distances2, avg_vector_centroid_distance)\n",
        "\n",
        "  # Find smallest average centroid distance for each\n",
        "  min_index_1 = np.argmin(distances1)\n",
        "  min_index_2 = np.argmin(distances2)\n",
        "\n",
        "  # Return which number distance is closest to\n",
        "  if distances1[min_index_1] < distances2[min_index_2]:\n",
        "    return min_index_1, train_speakers[min_index_1], 0\n",
        "  else:\n",
        "    return min_index_2, train_speakers[min_index_2], 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using zero and twelve"
      ],
      "metadata": {
        "id": "jMdjmfSgKzrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start with getting MFCCs and training for 0 and 12\n",
        "train_0_path = \"/content/Speaker_Recognition_EEC_201_Project/Zero-Training\"\n",
        "train_12_path = \"/content/Speaker_Recognition_EEC_201_Project/Twelve-Training\"\n",
        "\n",
        "# get train speakers for 0\n",
        "train0_speakers = []\n",
        "\n",
        "for filename in os.listdir(train_0_path):\n",
        "    file_path = os.path.join(train_0_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        train0_speakers.append(filename)\n",
        "\n",
        "# get mfccs for training 0 speakers\n",
        "train0_speaker_mfccs = []\n",
        "for speaker in train0_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(train_0_path, speaker))\n",
        "  train0_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# get train speakers for 12\n",
        "train12_speakers = []\n",
        "for filename in os.listdir(train_12_path):\n",
        "    file_path = os.path.join(train_12_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        train12_speakers.append(filename)\n",
        "\n",
        "# get mfccs for training 12 speakers\n",
        "train12_speaker_mfccs = []\n",
        "for speaker in train12_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(train_12_path, speaker))\n",
        "  train12_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# train codebooks\n",
        "codeBooks = train_two(train0_speakers, train0_speaker_mfccs, train12_speakers, train12_speaker_mfccs)\n",
        "\n",
        "# get test speakers for 0\n",
        "test_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Zero-Testing'\n",
        "test0_speakers = []\n",
        "for filename in os.listdir(test_folder_path):\n",
        "    file_path = os.path.join(test_folder_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        test0_speakers.append(filename)\n",
        "\n",
        "# Get test 0 speaker MFCCs\n",
        "test0_speaker_mfccs = []\n",
        "for speaker in test0_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(test_folder_path, speaker))\n",
        "  test0_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# get test speakers for 12\n",
        "test_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Twelve-Testing'\n",
        "test12_speakers = []\n",
        "for filename in os.listdir(test_folder_path):\n",
        "    file_path = os.path.join(test_folder_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        test12_speakers.append(filename)\n",
        "\n",
        "# Get test 12 speaker MFCCs\n",
        "test12_speaker_mfccs = []\n",
        "for speaker in test12_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(test_folder_path, speaker))\n",
        "  test12_speaker_mfccs.append(speaker_mfcc)"
      ],
      "metadata": {
        "id": "r6vEO2UBHAwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference Prediction for both 0 and 12\n",
        "num_correct_train = 0\n",
        "# reference prediction for training set 0\n",
        "for train_speaker, speaker_mfcc in enumerate(train0_speaker_mfccs):\n",
        "  prediction, predict_name, numb_0_12 = predict_two(codeBooks, speaker_mfcc, train0_speakers)\n",
        "  if predict_name == train0_speakers[train_speaker]:\n",
        "    if(numb_0_12 == 0):\n",
        "      num_correct_train += 1\n",
        "      print(f\"CORRECT: train_speaker: {train0_speakers[train_speaker]} predicted as: {train0_speakers[prediction]}\")\n",
        "      print(f\"0 predicted as 0\")\n",
        "    else:\n",
        "      print(f\"INCORRECT: train_speaker: {train0_speakers[train_speaker]} predicted as: {train0_speakers[prediction]}\")\n",
        "      print(f\"0 predicted as 12\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: train_speaker: {train0_speakers[train_speaker]} predicted as: {train0_speakers[prediction]}\")\n",
        "    if(numb_0_12 == 0):\n",
        "      print(f\"0 predicted as 0\")\n",
        "    else:\n",
        "      print(f\"0 predicted as 12\")\n",
        "\n",
        "# reference prediction for training set 12\n",
        "for test_speaker, speaker_mfcc in enumerate(train12_speaker_mfccs):\n",
        "  prediction, predict_name, numb_0_12 = predict_two(codeBooks, speaker_mfcc, train12_speakers)\n",
        "  if predict_name == train12_speakers[test_speaker]:\n",
        "    if(numb_0_12 == 1):\n",
        "      num_correct_train += 1\n",
        "      print(f\"CORRECT: train_speaker: {train12_speakers[test_speaker]} predicted as: {train12_speakers[prediction]}\")\n",
        "    else:\n",
        "      print(f\"INCORRECT: train_speaker: {train12_speakers[test_speaker]} predicted as: {train12_speakers[prediction]}\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: train_speaker: {train12_speakers[test_speaker]} predicted as: {train12_speakers[prediction]}\")\n",
        "  print(f\"12 predicted as {numb_0_12}\")\n",
        "\n",
        "print(f\"Accuracy: {num_correct_train * 100 / (len(train12_speaker_mfccs)*2)}%\")"
      ],
      "metadata": {
        "id": "Lb_C8OKJMYKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Prediction for both 0 and 12\n",
        "num_correct = 0\n",
        "# Predictions for test set 0\n",
        "for test_speaker, speaker_mfcc in enumerate(test0_speaker_mfccs):\n",
        "  prediction, predict_name, numb_0_12 = predict_two(codeBooks, speaker_mfcc, train0_speakers)\n",
        "  if predict_name == test0_speakers[test_speaker]:\n",
        "    if(numb_0_12 == 0):\n",
        "      num_correct += 1\n",
        "      print(f\"CORRECT: test_speaker: {test0_speakers[test_speaker]} predicted as: {train0_speakers[prediction]}\")\n",
        "      print(f\"0 predicted as 0\")\n",
        "    else:\n",
        "      print(f\"INCORRECT: test_speaker: {test0_speakers[test_speaker]} predicted as: {train0_speakers[prediction]}\")\n",
        "      print(f\"0 predicted as 12\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: test_speaker: {test0_speakers[test_speaker]} predicted as: {train0_speakers[prediction]}\")\n",
        "    if(numb_0_12 == 0):\n",
        "      print(f\"0 predicted as 0\")\n",
        "    else:\n",
        "      print(f\"0 predicted as 12\")\n",
        "\n",
        "# Predictions for test set 12\n",
        "for test_speaker, speaker_mfcc in enumerate(test12_speaker_mfccs):\n",
        "  prediction, predict_name, numb_0_12 = predict_two(codeBooks, speaker_mfcc, train12_speakers)\n",
        "  if predict_name == test12_speakers[test_speaker]:\n",
        "    if(numb_0_12 == 1):\n",
        "      num_correct += 1\n",
        "      print(f\"CORRECT: test_speaker: {test12_speakers[test_speaker]} predicted as: {train12_speakers[prediction]}\")\n",
        "      print(f\"12 predicted as 12\")\n",
        "    else:\n",
        "      print(f\"INCORRECT: test_speaker: {test12_speakers[test_speaker]} predicted as: {train12_speakers[prediction]}\")\n",
        "      print(f\"12 predicted as 0\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: test_speaker: {test12_speakers[test_speaker]} predicted as: {train12_speakers[prediction]}\")\n",
        "    if(numb_0_12 == 1):\n",
        "      print(f\"12 predicted as 12\")\n",
        "    else:\n",
        "      print(f\"12 predicted as 0\")\n",
        "\n",
        "print(f\"Accuracy: {num_correct * 100 / (len(test12_speaker_mfccs)*2)}%\")"
      ],
      "metadata": {
        "id": "yGJ21G4jMt1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a5UplijrZCS"
      },
      "source": [
        "### Test 10b\n",
        "#### Question 3: If we use \"eleven\" to identify speakers, what is the accuracy versus the system that uses \"five\"?\n",
        "\n",
        "Using \"five\" had an accuracy of about 91.3% and using \"eleven\" had an accuracy of about 86.95%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHTUn1yJqChh"
      },
      "source": [
        "#### Train Using 5 and 11 speeches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3rS9F0mqHKI"
      },
      "outputs": [],
      "source": [
        "# get mfccs for all train 5 speakers\n",
        "train5_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Five Training'\n",
        "\n",
        "train5_speakers = []\n",
        "\n",
        "# verify files and put filenames into train5_speakers\n",
        "for filename in os.listdir(train5_folder_path):\n",
        "    file_path = os.path.join(train5_folder_path, filename)\n",
        "    if os.path.isfile(file_path):  # Ensure it's a file, not a directory\n",
        "        train5_speakers.append(filename)\n",
        "\n",
        "# Find MFCCs for train 5\n",
        "train5_speaker_mfccs = []\n",
        "for speaker in train5_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(train5_folder_path, speaker))\n",
        "  train5_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# train codebooks for speech 5\n",
        "codeBooks_5 = train(train5_speaker_mfccs)\n",
        "\n",
        "# get mfccs for all train 11 speakers\n",
        "train11_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Eleven Training'\n",
        "\n",
        "train11_speakers = []\n",
        "\n",
        "# verify files and put filenames into train11_speakers\n",
        "for filename in os.listdir(train11_folder_path):\n",
        "    file_path = os.path.join(train11_folder_path, filename)\n",
        "    if os.path.isfile(file_path):  # Ensure it's a file, not a directory\n",
        "        train11_speakers.append(filename)\n",
        "\n",
        "train11_speaker_mfccs = []\n",
        "\n",
        "# Find MFCCs for train 11\n",
        "for speaker in train11_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(train11_folder_path, speaker))\n",
        "  train11_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# train codebooks for speech 11\n",
        "codeBooks_11 = train(train11_speaker_mfccs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39UWhmcFrfvI"
      },
      "source": [
        "##### Using \"five\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKXRhuVqrofL"
      },
      "outputs": [],
      "source": [
        "# get mfccs for all test speakers\n",
        "test_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Five Test'\n",
        "\n",
        "test5_speakers = []\n",
        "\n",
        "# verify files and put filenames into train5_speakers\n",
        "for filename in os.listdir(test_folder_path):\n",
        "    file_path = os.path.join(test_folder_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        test5_speakers.append(filename)\n",
        "\n",
        "# Find MFCCs for train 5\n",
        "test5_speaker_mfccs = []\n",
        "for speaker in test5_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(test_folder_path, speaker))\n",
        "  test5_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# reference prediction with training speakers\n",
        "num_correct_train = 0\n",
        "for train_speaker, speaker_mfcc in enumerate(train5_speaker_mfccs):\n",
        "  prediction = predict(codeBooks_5, speaker_mfcc)\n",
        "  if train5_speakers[prediction] == train5_speakers[train_speaker]:\n",
        "    num_correct_train += 1\n",
        "    print(f\"CORRECT: train_speaker: {train5_speakers[train_speaker]} predicted as: {train5_speakers[prediction]}\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: train_speaker: {train5_speakers[train_speaker]} predicted as: {train5_speakers[prediction]}\")\n",
        "\n",
        "print(f\"Accuracy: {num_correct_train * 100 / len(train5_speaker_mfccs)}%\")\n",
        "\n",
        "# prediction with test speakers\n",
        "num_correct = 0\n",
        "for test_speaker, speaker_mfcc in enumerate(test5_speaker_mfccs):\n",
        "  prediction = predict(codeBooks_5, speaker_mfcc)\n",
        "\n",
        "  if train5_speakers[prediction] == test5_speakers[test_speaker]:\n",
        "    num_correct += 1\n",
        "    print(f\"CORRECT: test_speaker: {test5_speakers[test_speaker]} predicted as: {train5_speakers[prediction]}\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: test_speaker: {test5_speakers[test_speaker]} predicted as: {train5_speakers[prediction]}\")\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {num_correct * 100 / len(test5_speaker_mfccs)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixx5EwUnrowg"
      },
      "source": [
        "Using \"eleven\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsQP_ITErqMQ"
      },
      "outputs": [],
      "source": [
        "# get mfccs for all test speakers\n",
        "test_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Eleven Test'\n",
        "\n",
        "test11_speakers = []\n",
        "\n",
        "# verify files and put filenames into train5_speakers\n",
        "for filename in os.listdir(test_folder_path):\n",
        "    file_path = os.path.join(test_folder_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        test11_speakers.append(filename)\n",
        "\n",
        "# Find MFCCs for train 11\n",
        "test11_speaker_mfccs = []\n",
        "for speaker in test11_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(test_folder_path, speaker))\n",
        "  test11_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# reference prediction with training speakers\n",
        "num_correct_train = 0\n",
        "for train_speaker, speaker_mfcc in enumerate(train11_speaker_mfccs):\n",
        "  prediction = predict(codeBooks_11, speaker_mfcc)\n",
        "  if train11_speakers[prediction] == train11_speakers[train_speaker]:\n",
        "    num_correct_train += 1\n",
        "    print(f\"CORRECT: train_speaker: {train11_speakers[train_speaker]} predicted as: {train11_speakers[prediction]}\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: train_speaker: {train11_speakers[train_speaker]} predicted as: {train11_speakers[prediction]}\")\n",
        "\n",
        "print(f\"Accuracy: {num_correct_train * 100 / len(train11_speaker_mfccs)}%\")\n",
        "\n",
        "# prediction with test speakers\n",
        "num_correct = 0\n",
        "for test_speaker, speaker_mfcc in enumerate(test11_speaker_mfccs):\n",
        "  prediction = predict(codeBooks_11, speaker_mfcc)\n",
        "\n",
        "  if train11_speakers[prediction] == test11_speakers[test_speaker]:\n",
        "    num_correct += 1\n",
        "    print(f\"CORRECT: test_speaker: {test11_speakers[test_speaker]} predicted as: {train11_speakers[prediction]}\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: test_speaker: {test11_speakers[test_speaker]} predicted as: {train11_speakers[prediction]}\")\n",
        "\n",
        "print(f\"Accuracy: {num_correct * 100 / len(test11_speaker_mfccs)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kNksH99qcnj"
      },
      "source": [
        "#### Question 4: How well do they compare against test in 10a using zero/twelve?\n",
        "\n",
        "The accuracy of the system when identifying which speaker and whether the speech is \"five\" or \"eleven\" is 89.13%. This is more accurate than the system that was using \"zero\" and \"twelve\", which had a 69.44% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi2VdQysqXyu"
      },
      "source": [
        "Using \"five\" and \"eleven\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfWrG3PSVPSa"
      },
      "outputs": [],
      "source": [
        "# Start with getting MFCCs and training for 5 and 11\n",
        "train_5_path = \"/content/Speaker_Recognition_EEC_201_Project/Five Training\"\n",
        "train_11_path = \"/content/Speaker_Recognition_EEC_201_Project/Eleven Training\"\n",
        "\n",
        "# get train speakers for 5\n",
        "train5_speakers = []\n",
        "\n",
        "for filename in os.listdir(train_5_path):\n",
        "    file_path = os.path.join(train_5_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        train5_speakers.append(filename)\n",
        "\n",
        "# get mfccs for training 5 speakers\n",
        "train5_speaker_mfccs = []\n",
        "for speaker in train5_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(train_5_path, speaker))\n",
        "  train5_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# get train speakers for 11\n",
        "train11_speakers = []\n",
        "for filename in os.listdir(train_11_path):\n",
        "    file_path = os.path.join(train_11_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        train11_speakers.append(filename)\n",
        "\n",
        "# get mfccs for training 11 speakers\n",
        "train11_speaker_mfccs = []\n",
        "for speaker in train11_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(train_11_path, speaker))\n",
        "  train11_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# train codebooks\n",
        "codeBooks = train_two(train5_speakers, train5_speaker_mfccs, train11_speakers, train11_speaker_mfccs)\n",
        "\n",
        "# get test speakers for 5\n",
        "test_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Five Test'\n",
        "test5_speakers = []\n",
        "for filename in os.listdir(test_folder_path):\n",
        "    file_path = os.path.join(test_folder_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        test5_speakers.append(filename)\n",
        "\n",
        "# Get test 5 speaker MFCCs\n",
        "test5_speaker_mfccs = []\n",
        "for speaker in test5_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(test_folder_path, speaker))\n",
        "  test5_speaker_mfccs.append(speaker_mfcc)\n",
        "\n",
        "# get test speakers for 11\n",
        "test_folder_path = '/content/Speaker_Recognition_EEC_201_Project/Eleven Test'\n",
        "test11_speakers = []\n",
        "for filename in os.listdir(test_folder_path):\n",
        "    file_path = os.path.join(test_folder_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        test11_speakers.append(filename)\n",
        "\n",
        "# Get test 11 speaker MFCCs\n",
        "test11_speaker_mfccs = []\n",
        "for speaker in test11_speakers:\n",
        "  speaker_mfcc = mfcc(os.path.join(test_folder_path, speaker))\n",
        "  test11_speaker_mfccs.append(speaker_mfcc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYPjvkfy8tGe"
      },
      "outputs": [],
      "source": [
        "# Reference Prediction for both 5 and 11\n",
        "num_correct_train = 0\n",
        "# reference prediction for training set 5\n",
        "for train_speaker, speaker_mfcc in enumerate(train5_speaker_mfccs):\n",
        "  prediction, predict_name, numb_5_11 = predict_two(codeBooks, speaker_mfcc, train5_speakers)\n",
        "  if predict_name == train5_speakers[train_speaker]:\n",
        "    if(numb_5_11 == 0):\n",
        "      num_correct_train += 1\n",
        "      print(f\"CORRECT: train_speaker: {train5_speakers[train_speaker]} predicted as: {train5_speakers[prediction]}\")\n",
        "      print(f\"5 predicted as 5\")\n",
        "    else:\n",
        "      print(f\"INCORRECT: train_speaker: {train5_speakers[train_speaker]} predicted as: {train5_speakers[prediction]}\")\n",
        "      print(f\"5 predicted as 11\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: train_speaker: {train5_speakers[train_speaker]} predicted as: {train5_speakers[prediction]}\")\n",
        "    if(numb_5_11 == 0):\n",
        "      print(f\"5 predicted as 5\")\n",
        "    else:\n",
        "      print(f\"5 predicted as 11\")\n",
        "\n",
        "# reference prediction for training set 11\n",
        "for test_speaker, speaker_mfcc in enumerate(train11_speaker_mfccs):\n",
        "  prediction, predict_name, numb_5_11 = predict_two(codeBooks, speaker_mfcc, train11_speakers)\n",
        "  if predict_name == train11_speakers[test_speaker]:\n",
        "    if(numb_5_11 == 1):\n",
        "      num_correct_train += 1\n",
        "      print(f\"CORRECT: train_speaker: {train11_speakers[test_speaker]} predicted as: {train11_speakers[prediction]}\")\n",
        "      print(f\"11 predicted as 11\")\n",
        "    else:\n",
        "      print(f\"INCORRECT: train_speaker: {train11_speakers[test_speaker]} predicted as: {train11_speakers[prediction]}\")\n",
        "      print(f\"11 predicted as 5\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: train_speaker: {train11_speakers[test_speaker]} predicted as: {train11_speakers[prediction]}\")\n",
        "    if(numb_5_11 == 1):\n",
        "      print(f\"11 predicted as 11\")\n",
        "    else:\n",
        "      print(f\"11 predicted as 5\")\n",
        "\n",
        "print(f\"Accuracy: {num_correct_train * 100 / (len(train11_speaker_mfccs)*2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVZur5Yu8x8o"
      },
      "outputs": [],
      "source": [
        "# Main Prediction for both 5 and 11\n",
        "num_correct = 0\n",
        "# Predictions for test set 5\n",
        "for test_speaker, speaker_mfcc in enumerate(test5_speaker_mfccs):\n",
        "  prediction, predict_name, numb_5_11 = predict_two(codeBooks, speaker_mfcc, train5_speakers)\n",
        "  if predict_name == test5_speakers[test_speaker]:\n",
        "    if(numb_5_11 == 0):\n",
        "      num_correct += 1\n",
        "      print(f\"CORRECT: test_speaker: {test5_speakers[test_speaker]} predicted as: {train5_speakers[prediction]}\")\n",
        "      print(f\"5 predicted as 5\")\n",
        "    else:\n",
        "      print(f\"INCORRECT: test_speaker: {test5_speakers[test_speaker]} predicted as: {train5_speakers[prediction]}\")\n",
        "      print(f\"5 predicted as 11\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: test_speaker: {test5_speakers[test_speaker]} predicted as: {train5_speakers[prediction]}\")\n",
        "    if(numb_5_11 == 0):\n",
        "      print(f\"5 predicted as 5\")\n",
        "    else:\n",
        "      print(f\"5 predicted as 11\")\n",
        "\n",
        "# Predictions for test set 11\n",
        "for test_speaker, speaker_mfcc in enumerate(test11_speaker_mfccs):\n",
        "  prediction, predict_name, numb_5_11 = predict_two(codeBooks, speaker_mfcc, train11_speakers)\n",
        "  if predict_name == test11_speakers[test_speaker]:\n",
        "    if(numb_5_11 == 1):\n",
        "      num_correct += 1\n",
        "      print(f\"CORRECT: test_speaker: {test11_speakers[test_speaker]} predicted as: {train11_speakers[prediction]}\")\n",
        "      print(f\"11 predicted as 11\")\n",
        "    else:\n",
        "      print(f\"INCORRECT: test_speaker: {test11_speakers[test_speaker]} predicted as: {train11_speakers[prediction]}\")\n",
        "      print(f\"11 predicted as 5\")\n",
        "  else:\n",
        "    print(f\"INCORRECT: test_speaker: {test11_speakers[test_speaker]} predicted as: {train11_speakers[prediction]}\")\n",
        "    if(numb_5_11 == 1):\n",
        "      print(f\"11 predicted as 11\")\n",
        "    else:\n",
        "      print(f\"11 predicted as 5\")\n",
        "\n",
        "print(f\"Accuracy: {num_correct * 100 / (len(test11_speaker_mfccs)*2)}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}